Easy way to measure latency

Suppose I specify in the XML the two tasks (source - end) between which I want to calculate the latency.
I know the connection graphs, and I can calculate a path of connections between the two task and find the ports in the middle.

What I have to do is take the time when source starts and propagate it throughout the ports till it reaches the last port of the last component.

- Source task
Engine: run onUpdate, before it save the time in a timestamp inside the task.
When there is the write, check if the port is in a latency graph and in case write in the port also the timestamp.

- Middle task
In the read check if there is a timestamp, in case store it inside the task timestamp.
When going to the write, add the the timestamp

- Final task.
Read the timestamp from the port and store it in the task.
When the onUpdate completes the engine calculate the time difference and accumulate it.
	Possibility to add a global class that manages the latencies.

Possible issues:
- What happen if the same task/port is in multiple latency path?
	- Possible solution allow just one latency path per application, or latency path that are disjoint
- How the different update rates change the calculus?.
	- Possible solution, consume the timestamp once read and update only if the timestamp is > 0



Every connection checks wheter the input port's task has a latency timer > 0 and in that case propagate it to 
to output port's task.

Should I put the latency_timer_ as atomic? probably yes





Target should reset timer of source, to avoid to override packet.
 - Issue: latency is not calculated at the service time rate but at every latency step, is it correct?
 I have to do so, no ohter choiche!




Cases tested:

- Simple pipeline: OK
- Simple pipeline with task with execution time > service time: OK
- Pipeline with diamond structure: OK
- Pipeline with a non triggered node: OK
	- Check if a inner node is periodic! 
